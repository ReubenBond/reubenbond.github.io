
<!DOCTYPE html>
<html lang="en">
        <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=Edge"/>

        <title>reublog - Performance Tuning for .NET Core</title>
        <meta name="description" content="reublog" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0">        

        <link type="application/rss+xml" rel="alternate" title="reublog" href="/feed.rss" />
                <link type="application/atom+xml" rel="alternate" title="reublog" href="/feed.atom" />
        <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/favicon.ico" type="image/x-icon">

        <link href="/assets/css/bootstrap.min.css" rel="stylesheet" />
        <link href="/assets/css/highlight.css" rel="stylesheet">
        <link href="/assets/css/clean-blog.css" rel="stylesheet" />
        <link href="/assets/css/master.css" rel="stylesheet" />
        <link href="/assets/css/font-awesome.min.css" rel="stylesheet" type="text/css">
        <link href='//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
        <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
        <link href="/assets/css/override.css" rel="stylesheet" />


        <meta name="application-name" content="reublog" />
        <meta name="msapplication-tooltip" content="reublog" />
        <meta name="msapplication-starturl" content="/" />

        <meta property="og:title" content="reublog - Performance Tuning for .NET Core" />
        <meta property="og:type" content="website" />
        <meta property="og:url" content="http://reubenbond.github.io/posts/dotnet-perf-tuning" />
        <!-- TODO: More social graph meta tags -->

        <script src="/assets/js/jquery.min.js"></script>
        <script src="/assets/js/bootstrap.min.js"></script>     
        <script src="/assets/js/highlight.pack.js"></script>   
        <script src="/assets/js/clean-blog.js"></script>
        <script src="/assets/js/d3.v3.min.js"></script>
        <script src="/assets/js/trianglify.min.js"></script>
        <script src="/assets/js/Please-compressed.js"></script>
        <script src="/assets/js/background-check.min.js"></script>
                
        <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
                <script src="/assets/js/html5shiv.js"></script>
                <script src="/assets/js/respond.min.js"></script>
        <![endif]-->
        
        


        </head>
        <body>
                
                <!-- Navigation -->
                <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
                        <div class="container-fluid">
                                <!-- Brand and toggle get grouped for better mobile display -->
                                <div class="navbar-header page-scroll">
                                        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar-collapse">
                                        <span class="sr-only">Toggle navigation</span>
                                        <span class="icon-bar"></span>
                                        <span class="icon-bar"></span>
                                        <span class="icon-bar"></span>
                                        </button>
                                        <a class="navbar-brand" href="/">reublog</a>
                                </div>
                        
                                <!-- Collect the nav links, forms, and other content for toggling -->
                                <div class="collapse navbar-collapse" id="navbar-collapse">
                                        <ul class="nav navbar-nav navbar-right">
                                                        <li><a href="/posts">Archive</a></li>
        <li><a href="/tags">Tags</a></li>
 
                                        </ul>
                                </div>
                                <!-- /.navbar-collapse -->
                        </div>
                        <!-- /.container -->
                </nav>
                
                <!-- Page Header -->
                <header class="intro-header" id="intro-header" style="background-image: url(&quot;/images/header.jpg&quot;)">
                        <div class="container">
                                <div class="row">
                                        <div class="col-md-12">

    
<div class="post-heading">
    <h1>Performance Tuning for .NET Core</h1>
    <div class="meta">        
Published on Tuesday, January 15, 2019<br>    </div>
        <div class="tags">
                    <a role="button" href="/tags/Hagar" class="btn btn-default btn-xs">Hagar</a>
                    <a role="button" href="/tags/Performance" class="btn btn-default btn-xs">Performance</a>
                    <a role="button" href="/tags/Projects" class="btn btn-default btn-xs">Projects</a>
                    <a role="button" href="/tags/Serialization" class="btn btn-default btn-xs">Serialization</a>
        </div>     
</div>
                                        </div>
                                </div>
                        </div>
                </header>
                
                <!-- Main Content -->
                <div class="container">
                        <div class="row">
                                <div id="content" class="col-md-12">
                                        

<p>Some of you may know I've been spending whatever time I can scrounge together grinding away at a new serialization library for .NET.
Serializers can be complicated beasts. They have to be reliable, flexible, and fast beyond reproach.
I won't convince you that serialization libraries have to be quick — in this post, that's a given. These are some tips from my experience in optimizing <a href="https://github.com/ReubenBond/Hagar">Hagar</a>'s performance. <strong>Most of this advice is applicable to other types of libraries or applications.</strong></p>
<p>A post on performance should have minimal overhead and get straight to the point, so this post focuses on tips to help you and things to look out for. <a href="https://twitter.com/reubenbond">Message me on Twitter</a> if something is unclear or you have something to add.</p>
<h2 id="maximize-profitable-inlining">Maximize profitable inlining</h2>
<p>Inlining is the technique where a method body is copied to the call site so that we can avoid the cost of jumping, argument passing, and register saving/restoring. In addition to saving those costs, inlining is a requirement for other optimizations. Roslyn (C#'s compiler) does not inline code. Instead, it is the responsibility of the JIT, as are most optimizations.</p>
<h3 id="use-static-throw-helpers">Use static <em>throw helpers</em></h3>
<p>A recent change which involved a significant refactor added around 20ns to the call duration for the serialization benchmark, increasing times from ~130ns to ~150ns (which is significant).</p>
<p>The culprit was the <code>throw</code> statement added in this helper method:</p>
<pre><code class="language-C#">public static Writer&lt;TBufferWriter&gt; CreateWriter&lt;TBufferWriter&gt;(
    this TBufferWriter buffer,
    SerializerSession session) where TBufferWriter : IBufferWriter&lt;byte&gt;
{
    if (session == null) throw new ArgumentNullException(nameof(session));
    return new Writer&lt;TBufferWriter&gt;(buffer, session);
}
</code></pre>
<p>When a method contains a <code>throw</code> statement, the JIT will not inline it. The common trick to solve this is to add a static &quot;throw helper&quot; method to do the dirty work for you, so the end result looks like this:</p>
<pre><code class="language-csharp">public static Writer&lt;TBufferWriter&gt; CreateWriter&lt;TBufferWriter&gt;(
    this TBufferWriter buffer,
    SerializerSession session) where TBufferWriter : IBufferWriter&lt;byte&gt;
{
    if (session == null) ThrowSessionNull();
    return new Writer&lt;TBufferWriter&gt;(buffer, session);

    void ThrowSessionNull() =&gt; throw new ArgumentNullException(nameof(session));
}
</code></pre>
<p>Crisis averted. The codebase uses this trick in many places. Having the <code>throw</code> statement in a separate method may have other benefits such as improving the locality of your commonly used code paths, but I'm unsure and haven't measured the impact.</p>
<h3 id="minimize-virtualinterface-calls">Minimize virtual/interface calls</h3>
<p>Virtual calls are slower than direct calls. If you're writing a performance critical system then there's a good chance you'll see virtual call overhead show up in the profiler. For one, virtual calls require indirection.</p>
<p>Devirtualization is a feature of many JIT Compilers, and RyuJIT is no exception. It's a complicated feature, though, and there are not many cases where RyuJIT can currently <em>prove</em> (to itself) that a method can be devirtualized and therefore become a candidate for inlining. Here are a couple of general tips for taking advantage of devirtualization, but I'm sure there are more (so let me know if you have any).</p>
<ul>
<li>Mark classes as <code>sealed</code> by default. When a class/method is marked as <code>sealed</code>, RyuJIT can take that into account and is likely able to inline a method call.</li>
<li>Mark <code>override</code> methods as <code>sealed</code> if possible.</li>
<li>Use concrete types instead of interfaces. Concrete types give the JIT more information, so it has a better chance of being able to inline your call.</li>
<li>Instantiate and use non-sealed objects in the same method (rather than having a 'create' method). RyuJIT can devirtualize non-sealed method calls when the type is definitely known, such as immediately after construction.</li>
<li>Use generic type constraints for polymorphic types so that they can be specialized using a concrete type and interface calls can be devirtualized. In Hagar, our core writer type is defined as follows:</li>
</ul>
<pre><code class="language-csharp">public ref struct Writer&lt;TBufferWriter&gt; where TBufferWriter : IBufferWriter&lt;byte&gt;
{
    private TBufferWriter output;
    // --- etc ---
</code></pre>
<p>All calls to methods on <code>output</code> in the CIL which Roslyn emits will be preceded by a <code>constrained</code> instruction which tells the JIT that instead of making a virtual/interface call, the call can be made to the precise method defined on <code>TBufferWriter</code>. This helps with devirtualization. All calls to methods defined on <code>output</code> are successfully devirtualized as a result. Here's <a href="https://github.com/dotnet/coreclr/issues/9908">a CoreCLR thread by Andy Ayers</a> on the JIT team which details current and future work for devirtualization.</p>
<h2 id="reduce-allocations">Reduce allocations</h2>
<p>.NET's garbage collector is a remarkable piece of engineering. GC allows for algorithmic optimizations for some lock-free data structures and also removes whole classes of bugs and lightens the developer's cognitive load. All things considered, garbage collection is a <em>tremendously</em> successful technique for memory management.</p>
<p>However, while the GC is a powerful work horse, it helps to lighten its load not only because it means your application will pause for collection less often (and more generally, less CPU time will be devoted to GC work), but also because lightening working set is beneficial for cache locality.</p>
<p>The rule-of-thumb for allocations is that they should either die in the first generation (Gen0) or live forever in the last (Gen2).</p>
<p>.NET uses a bump allocator where each thread allocates objects from its per-thread context by 'bumping' a pointer. For this reason, better cache locality can be achieved for short-lived allocations when they are allocated and used on the same thread.</p>
<p>For more info on .NET's GC, see <a href="https://twitter.com/matthewwarren">Matt Warren</a>'s blog post series, <a href="http://mattwarren.org/2016/02/04/learning-how-garbage-collectors-work-part-1/"><em>Learning How Garbage Collectors Work</em></a> here and pre-order <a href="https://twitter.com/konradkokosa">Konrad Kokosa</a>'s book, <a href="https://prodotnetmemory.com/"><em>Pro .NET Memory Management</em>  here</a>. Also check out his fantastic free <a href="https://prodotnetmemory.com/data/netmemoryposter.pdf">.NET memory management poster here</a>, it's a great reference.</p>
<h3 id="pool-buffersobjects">Pool buffers/objects</h3>
<p>Hagar itself doesn't manage buffers but instead defers the responsibility to the user. This might sound onerous but it's not, since it's compatible with <a href="https://blogs.msdn.microsoft.com/dotnet/2018/07/09/system-io-pipelines-high-performance-io-in-net/"><code>System.IO.Pipelines</code></a>. Therefore, we can take advantage of the high performance buffer pooling which the default <code>Pipe</code> provides by means of <code>System.Buffers.ArrayPool&lt;T&gt;</code>.</p>
<p>Generally speaking, reusing buffers lets you put much less pressure on the GC - your users will be thankful. Don't write your own buffer pool, unless you truly need to, though - those times have passed.</p>
<h3 id="avoid-boxing">Avoid boxing</h3>
<p>Wherever possible, do not box value types by casting them to a reference type. This is common advice, but it requires some consideration in your API design. In Hagar, interface and method definitions which might accept value types are made generic so that they can be specialized to the precise type and avoid boxing/unboxing costs. As a result, there is no hot-path boxing. Boxing is still present in some cases, such as string formatting for exception methods. Those particular boxing allocations can be removed by explicit <code>.ToString()</code> calls on the arguments.</p>
<h3 id="reduce-closure-allocations">Reduce closure allocations</h3>
<p>Allocate closures only once and store the result for repeated use. For example, it's common to pass a delegate to <code>ConcurrentDictionary&lt;K, V&gt;.GetOrAdd</code>. Instead of writing the delegate as an inline lambda, define is as a private field on the class. Here an example from the optional <code>ISerializable</code> support package in Hagar:</p>
<pre><code class="language-csharp">private readonly Func&lt;Type, Action&lt;object, SerializationInfo, StreamingContext&gt;&gt; createConstructorDelegate;

public ObjectSerializer(SerializationConstructorFactory constructorFactory)
{
    // Other parameters/statements omitted.
    this.createConstructorDelegate = constructorFactory.GetSerializationConstructorDelegate;
}

// Later, on a hot code path:
var constructor = this.constructors.GetOrAdd(info.ObjectType, this.createConstructorDelegate);
</code></pre>
<h2 id="minimize-copying">Minimize copying</h2>
<p>.NET Core 2.0 and 2.1 and recent C# versions have made considerable strides in allowing library developers to eliminate data copying. The most notable addition is <code>Span&lt;T&gt;</code>, but it's also worth mentioning <code>in</code> parameter modifiers and <code>readonly struct</code>.</p>
<h3 id="use-spant-to-avoid-array-allocations-and-avoid-data-copying">Use <code>Span&lt;T&gt;</code> to avoid array allocations and avoid data copying</h3>
<p><code>Span&lt;T&gt;</code> and friends are a gigantic performance win for .NET, particularly .NET Core where they use an optimized representation to reduce their size, which required adding GC support for interior pointers. Interior pointers are managed references which point to within the bounds of an array, as opposed to only being able to point to the first element and therefore requiring an additional field containing an offset into the array. For more info on <code>Span&lt;T&gt;</code> and friends, read Stephen Toub's article, <a href="https://msdn.microsoft.com/en-us/magazine/mt814808.aspx"><em>All About Span: Exploring a New .NET Mainstay</em> here</a>.</p>
<p>Hagar makes extensive use of <code>Span&lt;T&gt;</code> because it allows us to cheaply create views over small sections of larger buffers to work with. Enough has been written on the subject that there's no use me writing more here.</p>
<h3 id="pass-structs-by-ref-to-minimize-on-stack-copies">Pass structs by <code>ref</code> to minimize on-stack copies</h3>
<p>Hagar uses two main structs, <code>Reader</code> &amp; <code>Writer&lt;TOutputBuffer&gt;</code>. These structs each contain several fields and are passed to almost every call along the serialization/deserialization call path.</p>
<p>Without intervention, each method call made with these structs would carry significant weight since the entire struct would need to be copied onto the stack for every call, not to mention any mutations would need to be copied back to the caller.</p>
<p>We can avoid that cost by passing these structs as <code>ref</code> parameters. C# also supports using <code>ref this</code> as the target for an extension method, which is very convenient. As far as I know, there's no way to ensure that a particular struct type is always passed by ref and this can lead to subtle bugs if you accidentally omit <code>ref</code> in the parameter list of a call, since the struct will be silently copied and modifications made by a method (eg, advancing a write pointer) will be lost.</p>
<h3 id="avoid-defensive-copies">Avoid defensive copies</h3>
<p>Roslyn has to do some work to guarantee some language invariants sometimes. When a <code>struct</code> is stored in a <code>readonly</code> field, the compiler will insert instructions to <em>defensively copy</em> that field before involving it in any operation which isn't guaranteed to <em>not</em> mutate it. Typically this means calls to method defined on the struct type itself because passing a struct as argument to a method defined on another type already requires copying the struct onto the stack (unless it's passed by <code>ref</code> or <code>in</code>).</p>
<p>This defensive copy can be avoided if the struct is defined as a <code>readonly struct</code>, which is a C# 7.2 language feature, enabled by adding <code>&lt;LangVersion&gt;7.2&lt;/LangVersion&gt;</code> to your csproj file.</p>
<p>Sometimes it's better to omit the <code>readonly</code> modifier on an otherwise immutable struct field if you are unable to define it as a <code>readonly struct</code>.</p>
<p>See Jon Skeet's NodaTime library as an example. In <a href="https://github.com/nodatime/nodatime/pull/1130">this PR</a>, Jon made most structs <code>readonly</code> and was therefore able to add the <code>readonly</code> modifier to fields holding those structs without negatively impacting performance.</p>
<h2 id="reduce-branching-branch-misprediction">Reduce branching &amp; branch misprediction</h2>
<p>Modern CPUs rely on having long pipelines of instructions which are processed with some concurrency. This involves the CPU analyzing instructions to determine which ones aren't reliant on previous instructions and also involves guessing which conditional jump statements are going to be taken. In order to do this, the CPU uses a component called the branch predictor which is responsible for guessing which branch will be taken. It typically does this by reading &amp; writing entries in a table, revising its prediction based upon what happened last time the conditional jump was executed.</p>
<p>When it guesses correctly, this prediction process provides a substantial speedup. When it mispredicts the branch (jump target), however, it needs to throw out all of the work performed in processing instructions after the branch and re-fill the pipeline with instructions from the correct branch before continuing execution.</p>
<p>The fastest branch is no branch. First try to minimize the number of branches, always measuring whether or not your alternative is faster. When you cannot eliminate a branch, try to minimize misprediction rates. This may involve <a href="https://stackoverflow.com/a/11227902/635314">using sorted data</a> or restructuring your code.</p>
<p>One strategy for eliminating a branch is to replace it with a lookup. Sometimes an algorithm can be made branch-free instead of using conditionals. Sometimes <a href="https://mijailovic.net/2018/06/06/sha256-armv8/">hardware</a> <a href="https://blogs.msdn.microsoft.com/dotnet/2018/10/10/using-net-hardware-intrinsics-api-to-accelerate-machine-learning-scenarios/">intrinsics</a> can be used to eliminate branching.</p>
<h1 id="other-miscellaneous-tips">Other miscellaneous tips</h1>
<ul>
<li>Avoid LINQ. LINQ is great in application code, but rarely belongs on a hot path in library/framework code. LINQ is difficult for the JIT to optimize (<code>IEnumerable&lt;T&gt;</code>...) and tends to be allocation-happy.</li>
<li>Use concrete types instead of interfaces or abstract types. This was mentioned above in the context of inlining, but this has other benefits. Perhaps the most common being that if you are iterating over a <code>List&lt;T&gt;</code>, it's best to <em>not</em> cast that list to <code>IEnumerable&lt;T&gt;</code> first (eg, by using LINQ or passing it to a method as an <code>IEnumerable&lt;T&gt;</code> parameter). The reason for this is that enumerating over a list using <code>foreach</code> uses a non-allocating <code>List&lt;T&gt;.Enumerator</code> struct, but when it's cast to <code>IEnumerable&lt;T&gt;</code>, that struct must be boxed to <code>IEnumerator&lt;T&gt;</code> for <code>foreach</code>.</li>
<li>Reflection is exceptionally useful in library code, but it <em>will</em> kill you if you give it the chance. Cache the results of reflection, consider generating delegates for accessors using IL or Roslyn, or better yet, use an existing library such as <a href="https://github.com/aspnet/Common/blob/ff87989d893b000aac1bfef0157c92be1f04f714/shared/Microsoft.Extensions.ObjectMethodExecutor.Sources/ObjectMethodExecutor.cs"><code>Microsoft.Extensions.ObjectMethodExecutor.Sources</code></a>, <a href="https://github.com/aspnet/Common/blob/ff87989d893b000aac1bfef0157c92be1f04f714/shared/Microsoft.Extensions.PropertyHelper.Sources/PropertyHelper.cs"><code>Microsoft.Extensions.PropertyHelper.Sources</code></a>, or <a href="https://github.com/mgravell/fast-member"><code>FastMember</code></a>.</li>
</ul>
<h1 id="library-specific-optimizations">Library-specific optimizations</h1>
<h2 id="optimize-generated-code">Optimize generated code</h2>
<p>Hagar uses Roslyn to generate C# code for the POCOs you want to serialize, and this C# code is included in your project at compile time. There are some optimizations which we can perform on the generated code to make things faster.</p>
<h3 id="avoid-virtual-calls-by-skipping-codec-lookup-for-well-known-types">Avoid virtual calls by skipping codec lookup for well-known types</h3>
<p>When complex objects contain well known fields such as <code>int</code>, <code>Guid</code>, <code>string</code>, the code generator will directly insert calls to the hand-coded codecs for those types instead of calling into the <code>CodecProvider</code> to retrieve an <code>IFieldCodec&lt;T&gt;</code> instance for that type. This lets the JIT inline those calls and avoids virtual/interface indirection.</p>
<h3 id="unimplemented-specialize-generic-types-at-runtime">(Unimplemented) Specialize generic types at runtime</h3>
<p>Similar to above, the code generator could generate code which uses specialization at runtime.</p>
<h2 id="pre-compute-constant-values-to-eliminate-some-branching">Pre-compute constant values to eliminate some branching</h2>
<p>During serialization, each field is prefixed with a header – usually a single byte – which tells the deserializer which field was encoded. This field header contains 3 pieces of info: the wire type of the field (fixed-width, length-prefixed, tag-delimited, referenced, etc), the schema type of the field (expected, well-known, previously-defined, encoded) which is used for polymorphism, and dedicates the last 3 bits to encoding the field id (if it's less than 7). In many cases, it's possible to know exactly what this header byte will be at compile time. If a field has a value type, then we know that the runtime type can never differ from the field type and we always know the field id.</p>
<p>Therefore, we can often save all of the work required to compute the header value and can directly embed it into code as a constant. This saves branching and generally eliminates a lot of IL code.</p>
<h2 id="choose-appropriate-data-structures">Choose appropriate data structures</h2>
<p>One of the big performance disadvantages Hagar has when compared to other serializers such as <a href="https://github.com/mgravell/protobuf-net">protobuf-net</a> (in its default configuration?) and <a href="https://github.com/neuecc/MessagePack-CSharp">MessagePack-CSharp</a> is that it supports cyclic graphs and therefore must track objects as they're serialized so that object cycles are not lost during deserialization. When this was first implemented, the core data structure was a <code>Dictionary&lt;object, int&gt;</code>. It was clear in initial benchmarking that reference tracking was a dominating cost. In particular, clearing the dictionary between messages was expensive. By switching to an array of structs instead, the cost of indexing and maintaining the collection is largely eliminated and reference tracking no longer appears in the benchmarks. There is a downside to this: for large object graphs it's likely that this new approach is slower. If that becomes an issue, we can decide to dynamically switch between implementations.</p>
<h2 id="choose-appropriate-algorithms">Choose appropriate algorithms</h2>
<p>Hagar spends a lot of time encoding/decoding variable-length integers, often referred to as varints, in order to reduce the size of the payload (which can be more compact for storage/transport). Many binary serializers use this technique, including <a href="https://developers.google.com/protocol-buffers/docs/encoding#varints">Protocol Buffers</a>. Even .NET's BinaryWriter uses this encoding. Here's a <a href="https://github.com/Microsoft/referencesource/blob/60a4f8b853f60a424e36c7bf60f9b5b5f1973ed1/mscorlib/system/io/binarywriter.cs#L414">snippet from the reference source</a>:</p>
<pre><code class="language-csharp">protected void Write7BitEncodedInt(int value) {
    // Write out an int 7 bits at a time.  The high bit of the byte,
    // when on, tells reader to continue reading more bytes.
    uint v = (uint) value;   // support negative numbers
    while (v &gt;= 0x80) {
        Write((byte) (v | 0x80));
        v &gt;&gt;= 7;
    }
    Write((byte)v);
}
</code></pre>
<p>Looking at this source, I want to point out that <a href="https://developers.google.com/protocol-buffers/docs/encoding#signed-integers">ZigZag encoding</a> may be more efficient for signed integers which contain negative values, rather than casting to <code>uint</code>.</p>
<p>VarInts in these serializers use an algorithm called Little Endian Base-128 or LEB128, which encodes up to 7 bits per byte. It uses the most significant bit of each byte to indicate whether or not another byte follows (1 = yes, 0 = no). This is a simple format but it may not be the fastest. It might turn out that PrefixVarint is faster. With PrefixVarint, all of those 1s from LEB128 are written in one shot, at the beginning of the payload. This may let us use <a href="https://mijailovic.net/2018/06/06/sha256-armv8/">hardware</a> <a href="https://blogs.msdn.microsoft.com/dotnet/2018/10/10/using-net-hardware-intrinsics-api-to-accelerate-machine-learning-scenarios/">intrinsics</a> to improve the speed of this encoding &amp; decoding. By moving the size information to the front, we may also be able to read more bytes at a time from the payload, reducing internal bookkeeping and improving performance. If someone wants to implement this in C#, I will happily take a PR if it turns out to be faster.</p>
<hr />
<p>Hopefully you've found something useful in this post. <a href="https://twitter.com/reubenbond">Let me know</a> if something is unclear or you have something to add. Since I started writing this, I've moved to Redmond and officially joined Microsoft on the <a href="https://github.com/dotnet/orleans">Orleans</a> team, working on some very exciting things.</p>



                                </div>
                        </div>
                </div>
                
                <hr>
                
                <!-- Footer -->
                <footer>
                        <div class="container">
        <div class="row">
                <div class="col-md-12 text-center">
                    <p class="copyright text-muted">
                        Copyright © 2019
                        <br />
                            <a href="/feed.rss"><i class="fa fa-rss"></i> RSS Feed</a>
                        |
                            <a href="/feed.atom"><i class="fa fa-rss"></i> Atom Feed</a>
                        <br />
                        <strong><a href="https://wyam.io">Generated by Wyam</a></strong>
                    </p>
                </div>
        </div>
</div>

                </footer> 

                
                <script>hljs.initHighlightingOnLoad();</script>


                <script>
                        BackgroundCheck.init({
                                targets: '.intro-header,.navbar',
                                images: '.intro-header'
                        });
                </script>
        </body>
</html>

